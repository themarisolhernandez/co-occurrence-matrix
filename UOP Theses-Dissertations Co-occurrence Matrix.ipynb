{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382f28e8",
   "metadata": {},
   "source": [
    "<left><font size=3>March 2, 2022 / [Marisol Hernandez](https://www.linkedin.com/in/marisol-y-hernandez/)</font></left>\n",
    "# <left><font size=6> *University of the Pacific*<br>Theses/Dissertations Similarity Matrix</font>  \n",
    "<left><font size=3>Building a similarity matrix using [d3.js](https://d3js.org) to analyze overlapping topics in dissertations.</font></left>\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "[I. Objective](#objective)  \n",
    "[II. Web Scraping](#scraping)  \n",
    "[III. Combine Data and Sample](#data)  \n",
    "[IV. Computing Pairwise Similarities](#pairwise)  \n",
    "[V. Preparing the JSON](#json)  \n",
    "[VI. Export the JSON](#export)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743eb816",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Sometimes we think we find the holy grail, that one piece of literature that perfectly supports our research. As you skim the paper, you find yourself begging for more. What else is out there? There has to be other related work out there. A great place to start when looking for related literature is to look at the resources cited in the bibliography. I said \"great,\" but is it really? \n",
    "\n",
    "There has to be **another way**, a more efficient, appealing, user-friendly solution.\n",
    "\n",
    "Introducing the similarity matrix. I went to work and developed a matrix diagram that visualizes overlapping topics in a sample of dissertations from my University. Each colored cell represents two published works and their similiarities; the darker the color, the greater the similarity.\n",
    "\n",
    "In doing so, I had two main jobs: **get the data** and **build the d3 visualization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197e8d2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d70991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from random import sample\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37866501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf7576",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "When a student completes their thesis or dissertation, their work is published on this site: https://scholarlycommons.pacific.edu/uop_etds/. With this site, I had to do the following:\n",
    "\n",
    "1. Find the article listing of each thesis/dissertation.\n",
    "2. Retrieve the link to the thesis/dissertation overview.\n",
    "3. From that page, retrieve the title, author, group (department), and abstract.\n",
    "\n",
    "First, using **requests** and **BeautifulSoup** I retrieve the contents of the URL. Additionally, I initialize several lists where I will store the data items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b026960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "authors = []\n",
    "groups = []\n",
    "keywords = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b1230",
   "metadata": {},
   "source": [
    "I will break the following into steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dc018b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,8):\n",
    "    url = 'https://scholarlycommons.pacific.edu/uop_etds/'\n",
    "    \n",
    "    if i == 1:\n",
    "        extension = 'index.html'\n",
    "        url = url + extension\n",
    "    else:\n",
    "        extension = 'index.' + str(i) + '.html'\n",
    "        url = url + extension\n",
    "    \n",
    "    # retrieve contents of url\n",
    "    response = requests.get(url)\n",
    "    soup= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # search for article listing\n",
    "    for string in soup.select(\"[class='article-listing']\"):\n",
    "        string = BeautifulSoup(str(string), \"html.parser\")\n",
    "\n",
    "        # retrieve article overview\n",
    "        articleListing = string.find('a').get('href')\n",
    "        response = requests.get(articleListing)\n",
    "        articleSoup = BeautifulSoup(response.text, \"html.parser\") \n",
    "\n",
    "        # retreive title\n",
    "        try:\n",
    "            title = articleSoup.find(\"meta\", property=\"og:title\")['content']\n",
    "            titles.append(title)\n",
    "        except:\n",
    "            titles.append(np.nan)\n",
    "\n",
    "        # retrieve authors\n",
    "        try:\n",
    "            author = articleSoup.find(\"meta\", property=\"article:author\")['content']\n",
    "            authors.append(author)\n",
    "        except:\n",
    "            authors.append(np.nan)\n",
    "\n",
    "        # retrieve group\n",
    "        try:\n",
    "            group = articleSoup.find('div', {'class':'element', 'id':'department'}).find('p').get_text()\n",
    "            groups.append(group)\n",
    "        except:\n",
    "            groups.append(np.nan)\n",
    "\n",
    "        # retrieve keywords\n",
    "        try:\n",
    "            keyword = articleSoup.find(\"meta\", attrs={\"name\":\"keywords\"})['content']\n",
    "            keywords.append(keyword)\n",
    "        except:\n",
    "            keywords.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea446e",
   "metadata": {},
   "source": [
    "### 1. Find the article listing of each thesis/dissertation.\n",
    "This is the first article listing. As you can see, the structure is of an HTML file. Note, I use the `prettify()` method just to better structure the print out, but it is not used in my code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bfb7f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"article-listing\">\n",
      " <strong>\n",
      "  Thesis - Pacific Access Restricted:\n",
      " </strong>\n",
      " <a href=\"https://scholarlycommons.pacific.edu/uop_etds/273\">\n",
      "  Human Cytochrome P450 3A4 Over-Expressing IEC-18 and MDCK Cell Lines as an In-Vitro Model to Assess Gut Permeability and the Enzyme Metabolism\n",
      " </a>\n",
      " , Swathi Vangala\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "string = soup.select(\"[class='article-listing']\")[0]\n",
    "string = BeautifulSoup(str(string), \"html.parser\")\n",
    "print(string.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b82cb",
   "metadata": {},
   "source": [
    "### 2. Retrieve the link to the thesis/dissertation overview.\n",
    "Above you may notice a URL. This is link to the thesis/dissertation overview. I retrieve this component from the HREF attribute of the anchor `<a>` tag. The HREF contains two components: the URL, which is the actual link, and the clickable text that appears on the page, called the \"anchor text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c80877ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://scholarlycommons.pacific.edu/uop_etds/273'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articleListing = string.find('a').get('href')\n",
    "articleListing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f4d2fa",
   "metadata": {},
   "source": [
    "Similar to the beginning, we can use **requests** and **BeautifulSoup** to retrieve the contents of this URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4c636b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <!-- inj yui3-seed: -->\n",
      "  <script src=\"//cdnjs.cloudflare.com/ajax/libs/yui/3.6.0/yui/yui-min.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <!-- Adobe Analytics SiteCatalyst -->\n",
      "  <script src=\"https://assets.adobedtm.com/376c5346e33126fdb6b2dbac81e307cbacfd7935/satelliteLib-fac053ad0cbd6e703a1df9a51f69fde523024cef.js\" type=\"text/javascript\">\n",
      "  </s\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(articleListing)\n",
    "articleSoup = BeautifulSoup(response.text, \"html.parser\") \n",
    "# First 500 characters\n",
    "print(articleSoup.prettify()[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11fd04",
   "metadata": {},
   "source": [
    "### 3. From that page, retrieve the title, author, group (department), and keywords.\n",
    "We can find the title, author, group (department) and abstract in this page. Below, I retrieve the title and author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6174547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Cytochrome P450 3A4 Over-Expressing IEC-18 and MDCK Cell Lines as an In-Vitro Model to Assess Gut Permeability and the Enzyme Metabolism\n"
     ]
    }
   ],
   "source": [
    "# retreive title\n",
    "title = articleSoup.find(\"meta\", property=\"og:title\")['content']\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "38a2121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swathi Vangala\n"
     ]
    }
   ],
   "source": [
    "# retreive author\n",
    "author = articleSoup.find(\"meta\", property=\"article:author\")['content']\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531db350",
   "metadata": {},
   "source": [
    "Similarily, I retrieve the group (department)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f9aba2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pharmaceutical and Chemical Sciences\n"
     ]
    }
   ],
   "source": [
    "# retrieve group\n",
    "group = articleSoup.find('div', {'class':'element', 'id':'department'}).find('p').get_text()\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae7a15",
   "metadata": {},
   "source": [
    "Lastly, I retrieve the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "99b0d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pharmacy sciences, Health and environmental sciences\n"
     ]
    }
   ],
   "source": [
    "# retrieve keywords\n",
    "keyword = articleSoup.find(\"meta\", attrs={\"name\":\"keywords\"})['content']\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93525d",
   "metadata": {},
   "source": [
    "## Combine Data And Sample\n",
    "Using the lists, I combine all the data into one dataframe. I then sample just 73 and add my professor's thesis in there for a total sample of 74 theses/dissertations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "81961d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'original title':titles, 'author':authors, 'group':groups, 'keywords':keywords})\n",
    "data['title'] = data['original title'] + ' by ' + data['author']\n",
    "\n",
    "data = data[['title', 'group', 'keywords']]\n",
    "data.dropna(inplace=True) # remove NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa25088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['group'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6b147074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>group</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASE STUDY ON INCLUSIVE DESIGN AND OPERATIONS ...</td>\n",
       "      <td>Sport Sciences</td>\n",
       "      <td>AIMFREE, disability, inclusion, inclusivity, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Capital Formation and Return Migration w...</td>\n",
       "      <td>Learning, Leadership and Change</td>\n",
       "      <td>Education, Asian studies, Southeast Asian stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female Muslim-American students' perceptions o...</td>\n",
       "      <td>Educational Administration and Leadership</td>\n",
       "      <td>Muslim students, United States, Discrimination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USING COMMUNITY CULTURAL WEALTH NARRATIVES OF ...</td>\n",
       "      <td>Educational Administration and Leadership</td>\n",
       "      <td>Capital, Community, Rural, Students, Education...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Predicting aqueous solubility of pharmaceutica...</td>\n",
       "      <td>Pharmaceutical and Chemical Sciences</td>\n",
       "      <td>Pharmacy sciences, Health and environmental sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  CASE STUDY ON INCLUSIVE DESIGN AND OPERATIONS ...   \n",
       "1  Human Capital Formation and Return Migration w...   \n",
       "2  Female Muslim-American students' perceptions o...   \n",
       "3  USING COMMUNITY CULTURAL WEALTH NARRATIVES OF ...   \n",
       "4  Predicting aqueous solubility of pharmaceutica...   \n",
       "\n",
       "                                       group  \\\n",
       "0                             Sport Sciences   \n",
       "1            Learning, Leadership and Change   \n",
       "2  Educational Administration and Leadership   \n",
       "3  Educational Administration and Leadership   \n",
       "4       Pharmaceutical and Chemical Sciences   \n",
       "\n",
       "                                            keywords  \n",
       "0  AIMFREE, disability, inclusion, inclusivity, p...  \n",
       "1  Education, Asian studies, Southeast Asian stud...  \n",
       "2  Muslim students, United States, Discrimination...  \n",
       "3  Capital, Community, Rural, Students, Education...  \n",
       "4  Pharmacy sciences, Health and environmental sc...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['group']=='Learning, Leadership and Change') | (data['group']=='Pharmaceutical and Chemical Sciences') |\n",
    "            (data['group']=='Dentistry') | (data['group']=='Department of Orthodontics') |\n",
    "            (data['group']=='Educational Administration and Leadership') | (data['group']=='Sport Sciences') |\n",
    "            (data['group']=='Health, Exercise, and Sport Sciences')]\n",
    "\n",
    "sample = data.sample(73, random_state=123)\n",
    "\n",
    "# Add Dana's dissertation\n",
    "dana = {'title':'How much do you care about education? Exploring fluctuations of public interest in education issues among top national priorities in the U.S. by Dana Nehoran',\n",
    "       'group':'Learning, Leadership and Change',\n",
    "       'keywords':'Education, Information science, Political science, Education, Mass Media, Natural Language Processing, Polls, Public Opinion Research, Topic Modeling'\n",
    "       }\n",
    "\n",
    "sample = sample.append(dana, ignore_index=True)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e13f9",
   "metadata": {},
   "source": [
    "## Topic Co-occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "25ac0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sample items into lists\n",
    "titles = list(sample['title'])\n",
    "groups = list(sample['group'])\n",
    "corpus = list(sample['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2b2c2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = corpus[0]\n",
    "\n",
    "co_occurenceLists = []\n",
    "\n",
    "for i in range(0, len(corpus)):\n",
    "    termCount = []\n",
    "    row = corpus[i].lower().split(', ')\n",
    "    for j in range(0, len(corpus)):\n",
    "        nextRow = corpus[j].lower().split(', ')\n",
    "        commonTerms = len([value for value in row if value in nextRow])\n",
    "        termCount.append(commonTerms)\n",
    "    co_occurenceLists.append(termCount)\n",
    "\n",
    "# Convert to array\n",
    "arr = np.array(co_occurenceLists)\n",
    "np.fill_diagonal(arr, 0) # fill the diagonal with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c228131",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7e9cc",
   "metadata": {},
   "source": [
    "Here, we are just preparing our data for the JSON file. In this first cell, I prepare the nodes with the following format, \n",
    "\n",
    "`{'group':group, 'index':index, 'name':name}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "15bc41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ''\n",
    "index = 0\n",
    "name = ''\n",
    "\n",
    "allNodes = []\n",
    "\n",
    "for i in range(0, len(corpus)):\n",
    "    group = groups[i]\n",
    "    index = i\n",
    "    name = titles[i]\n",
    "    \n",
    "    node = {'group':group, 'index':index, 'name':name}\n",
    "    allNodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "15c33288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'group': 'Sport Sciences',\n",
       "  'index': 0,\n",
       "  'name': 'CASE STUDY ON INCLUSIVE DESIGN AND OPERATIONS AT ONE CAMPUS RECREATION CENTER by Kelly Cartner'},\n",
       " {'group': 'Learning, Leadership and Change',\n",
       "  'index': 1,\n",
       "  'name': 'Human Capital Formation and Return Migration within Mong Communities in Rural/Semi-Rural Northern California by Chong Yang'},\n",
       " {'group': 'Educational Administration and Leadership',\n",
       "  'index': 2,\n",
       "  'name': \"Female Muslim-American students' perceptions of socio-cultural accommodation in California public high school by Shakera Azimi\"}]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 3 nodes\n",
    "allNodes[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65726021",
   "metadata": {},
   "source": [
    "Next, I develop the links. These essentially contain the scaled cosine similarity. These have the following format,\n",
    "\n",
    "`{'source':source, 'target':target, 'value':value}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5c680d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 0\n",
    "target = 0\n",
    "value = 0\n",
    "\n",
    "allLinks = []\n",
    "\n",
    "for i in range(0, len(corpus)):\n",
    "    for j in range(0, len(corpus)):\n",
    "        row = arr[i]\n",
    "        source = i\n",
    "        target = j\n",
    "        value = int(arr[i][j])\n",
    "    \n",
    "        link = {'source':source, 'target':target, 'value':value}\n",
    "        allLinks.append(link)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4be1a086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 0, 'target': 0, 'value': 0},\n",
       " {'source': 0, 'target': 1, 'value': 0},\n",
       " {'source': 0, 'target': 2, 'value': 0}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 3 links\n",
    "allLinks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13277c2f",
   "metadata": {},
   "source": [
    "## Export to JSON\n",
    "Lastly we export the data to JSON file. These file will essentially be used to develop the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "37ee4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {'nodes':allNodes, 'links':allLinks}\n",
    "\n",
    "with open(\"/Users/marisolhernandez/Desktop/SKAEL/Co-occurrence Matrix/data/data.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
